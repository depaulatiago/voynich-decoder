# ğŸ§¬ Voynich Manuscript Decoder

[![CI](https://github.com/depaulatiago/voynich-decoder/workflows/CI/badge.svg)](https://github.com/depaulatiago/voynich-decoder/actions)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

**AI-powered analysis of the Voynich Manuscript using statistical linguistics, machine learning, and comparative language analysis.**

This project implements a comprehensive pipeline to investigate patterns in the mysterious Voynich Manuscript through computational methods, combining statistical analysis, embeddings, language comparison, temporal evolution tracking, and visual overlays.

---

## ğŸ¯ Project Goals

Build a system that:

1. âœ… **Ingests** Voynich transcriptions (EVA/Takahashi format)
2. âœ… **Normalizes** text by removing markers and standardizing tokens
3. âœ… **Analyzes** statistical patterns (frequencies, n-grams, entropy, Zipf's law)
4. âœ… **Trains** embeddings (Word2Vec/FastText) on Voynich corpus
5. âœ… **Generates** semantic clusters and visualizations
6. âœ… **Compares** with historical languages (Hebrew, Arabic, Latin, English, Middle English)
7. âœ… **Tracks** temporal evolution across manuscript folios
8. âœ… **Creates** visual overlays on manuscript images
9. âœ… **Documents** hypotheses, analyses, and conclusions

> **Note:** This project does NOT attempt literal translation, but explores patterns, structures, and potential linguistic properties.

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/depaulatiago/voynich-decoder.git
cd voynich-decoder

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Run Smoke Test

```bash
chmod +x scripts/smoke_run.sh
./scripts/smoke_run.sh
```

**Expected output:** Complete pipeline execution in 30-60 seconds with reports generated in `reports/`.

ğŸ“– **Detailed guide:** See [docs/QUICKSTART.md](docs/QUICKSTART.md)

---

## ğŸ“Š Key Features

### 1. Statistical Analysis
- Token frequency distributions
- N-gram analysis (bigrams, trigrams)
- Shannon entropy calculations
- Zipf's law validation
- Type-token ratio metrics

### 2. Semantic Embeddings
- Word2Vec and FastText models
- Sentence transformers (BERT-based)
- Semantic similarity clustering
- Dimensionality reduction (t-SNE, UMAP)

### 3. Language Comparison
- Jensen-Shannon Divergence (JSD) scoring
- Comparison with 6 historical languages:
  - Hebrew
  - Arabic (Quran)
  - Latin
  - English
  - Middle English
  - Hebrew (raw)
- Statistical pattern matching

### 4. Timeline Analysis
- Token usage evolution across folios
- Vocabulary diversity tracking (type-token ratio)
- Vocabulary shift detection (JSD, Jaccard similarity)
- Section boundary identification
- Temporal pattern visualization

### 5. Visual Overlay System
- Color-coded token annotations
- Bounding box visualization
- Manuscript image integration
- High-resolution output (300 DPI)

### 6. AI Hypothesis Generation
- Rule-based pattern detection
- LLM-powered interpretation
- Hypothesis aggregation and scoring
- Confidence metrics

---

## ğŸ“ Project Structure

```
voynich-decoder/
â”œâ”€â”€ data/                    # Data files (gitignored)
â”‚   â”œâ”€â”€ corpora/            # Historical language corpora
â”‚   â”œâ”€â”€ external/           # Manuscript images
â”‚   â”œâ”€â”€ processed/          # Pipeline outputs
â”‚   â””â”€â”€ raw/                # Raw transcriptions
â”‚
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ QUICKSTART.md       # Quick start guide
â”‚   â”œâ”€â”€ STRUCTURE.md        # Detailed structure
â”‚   â”œâ”€â”€ project/            # Project documentation
â”‚   â””â”€â”€ technical/          # Technical specs
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks (4 notebooks)
â”‚   â”œâ”€â”€ results_analysis.ipynb
â”‚   â”œâ”€â”€ takahashi_analysis.ipynb
â”‚   â”œâ”€â”€ timeline_analysis.ipynb
â”‚   â””â”€â”€ visual_overlay.ipynb
â”‚
â”œâ”€â”€ reports/                # Analysis outputs
â”‚   â”œâ”€â”€ final_report.md     # Main report (3,494 words)
â”‚   â”œâ”€â”€ process_log.md      # Development log (3,133 words)
â”‚   â”œâ”€â”€ analysis_report.md  # Results interpretation
â”‚   â”œâ”€â”€ comparison/         # Language comparison results
â”‚   â”œâ”€â”€ figures/            # Visualizations
â”‚   â”œâ”€â”€ hypotheses/         # Generated hypotheses
â”‚   â””â”€â”€ metrics/            # Performance metrics
â”‚
â”œâ”€â”€ src/                    # Source code (25 modules)
â”‚   â”œâ”€â”€ analysis/           # Advanced analysis
â”‚   â”œâ”€â”€ analytics/          # Statistical analysis
â”‚   â”œâ”€â”€ compare/            # Language comparison
â”‚   â”œâ”€â”€ embeddings/         # Embedding models
â”‚   â”œâ”€â”€ ingest/             # Data ingestion
â”‚   â”œâ”€â”€ llm/                # LLM integration
â”‚   â”œâ”€â”€ pipeline/           # Pipeline orchestration
â”‚   â”œâ”€â”€ utils/              # Utilities
â”‚   â”œâ”€â”€ visualization/      # Visualization
â”‚   â””â”€â”€ cli.py              # Command-line interface
â”‚
â”œâ”€â”€ scripts/                # Utility scripts
â”‚   â””â”€â”€ smoke_run.sh        # Smoke test pipeline
â”‚
â””â”€â”€ tests/                  # Test suite
    â””â”€â”€ test_smoke_pipeline.py
```

ğŸ“– **Full structure:** See [docs/STRUCTURE.md](docs/STRUCTURE.md)

---

## ğŸ”¬ Key Findings

### Statistical Patterns
- **Zipf Slope:** -0.55 (vs. -1.0 expected) â†’ suggests agglutinative morphology
- **Entropy:** 3.09 bits â†’ moderate unpredictability
- **Top Token Concentration:** 64.3% â†’ high repetitiveness (cipher-like)

### Language Similarity
- **Hebrew/Arabic:** JSD = 0.500 (closest match)
- **Latin:** JSD = 0.955 (contradicts popular hypothesis)
- **Conclusion:** Statistical evidence supports Semitic language family connection

### Temporal Evolution
- **Vocabulary Diversity:** Mean 0.867 Â± 0.298 (moderate variation)
- **Vocabulary Shifts:** Mean JSD = 0.529 between adjacent folios
- **Section Boundaries:** Clear statistical shifts detected (e.g., folios 24vâ†’25r: JSD=0.693)

### Hypothesis Quality
- **35 hypotheses generated**
- **28.6% unique patterns**
- **85.7% generic** (requires LLM upgrade)

ğŸ“– **Full analysis:** See [reports/final_report.md](reports/final_report.md)

---

## ğŸ› ï¸ Usage

### Command-Line Interface

```bash
# View all commands
python src/cli.py --help

# Run full pipeline
python src/pipeline/run_full_pipeline.py

# Generate timeline analysis
python src/analysis/temporal_evolution.py

# Create visual overlays
python src/visualization/overlay.py

# Compare with languages
python src/compare/compare_corpora.py \
  --voynich data/processed/voynich_run.jsonl \
  --corpora data/corpora \
  --out reports/comparison
```

### Python API

```python
from analysis.temporal_evolution import TemporalAnalyzer

# Run timeline analysis
analyzer = TemporalAnalyzer(
    token_coords_path='data/processed/token_coords.jsonl',
    output_dir='reports/figures/timeline'
)
analyzer.run_full_analysis()
```

### Jupyter Notebooks

```bash
# Launch Jupyter
jupyter notebook

# Open notebooks/results_analysis.ipynb
```

---

## ğŸ“š Documentation

- **[Quick Start Guide](docs/QUICKSTART.md)** - Get started in 5 minutes
- **[Project Structure](docs/STRUCTURE.md)** - Detailed file organization
- **[Final Report](reports/final_report.md)** - Comprehensive scientific report
- **[Process Log](reports/process_log.md)** - Development documentation
- **[Timeline Analysis](docs/project/TIMELINE_COMPLETE.md)** - Temporal evolution findings
- **[Technical Specs](docs/technical/)** - Data format specifications

---

## ğŸ§ª Testing

```bash
# Run smoke test
./scripts/smoke_run.sh

# Run pytest (if available)
pytest tests/

# Check specific module
python -m pytest tests/test_smoke_pipeline.py -v
```

---

## ğŸ“Š Results

### Generated Outputs

After running the pipeline, you'll find:

- **Reports** (`reports/`)
  - Statistical analysis
  - Language comparisons
  - Hypotheses summaries
  - Final scientific report

- **Visualizations** (`reports/figures/`)
  - Token frequency heatmaps
  - Vocabulary evolution plots
  - Vocabulary shift analysis
  - Visual overlays on manuscript images

- **Data** (`data/processed/`)
  - Tokenized transcriptions
  - Token coordinates
  - N-grams and statistics

---

## ğŸ”§ Development

### Project Dependencies

Core:
- `pandas` - Data manipulation
- `numpy` - Numerical operations
- `matplotlib`, `seaborn` - Visualization
- `scipy` - Statistical functions
- `gensim` - Word embeddings
- `sentence-transformers` - BERT embeddings
- `hdbscan` - Clustering
- `Pillow` - Image processing

Optional:
- `torch` - Deep learning (for faster embeddings)
- `transformers` - LLM integration
- `jupyter` - Interactive notebooks

### Adding New Features

1. **New Analysis Module:**
   ```bash
   # Create module in src/analysis/
   touch src/analysis/my_analysis.py
   
   # Add to CLI in src/cli.py
   ```

2. **New Corpus:**
   ```bash
   # Add text file to data/corpora/
   cp my_corpus.txt data/corpora/
   
   # Run comparison
   python src/cli.py compare-corpora
   ```

3. **New Visualization:**
   ```bash
   # Add to src/visualization/
   # Update notebooks for interactive exploration
   ```

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

---

## ğŸ“œ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Voynich Manuscript** - Yale Beinecke Rare Book Library (MS 408)
- **Takahashi Transcription** - For providing structured transcription data
- **Historical Corpora** - Various open-source language datasets
- **Open Source Community** - For the excellent libraries used in this project

---

## ğŸ“§ Contact

- **Author:** Tiago de Paula
- **Repository:** [github.com/depaulatiago/voynich-decoder](https://github.com/depaulatiago/voynich-decoder)
- **Issues:** [GitHub Issues](https://github.com/depaulatiago/voynich-decoder/issues)

---

## ğŸ“ Citation

If you use this work in your research, please cite:

```bibtex
@software{voynich_decoder_2025,
  author = {de Paula, Tiago},
  title = {Voynich Manuscript Decoder: AI-Powered Analysis Pipeline},
  year = {2025},
  url = {https://github.com/depaulatiago/voynich-decoder}
}
```

---

**Status:** âœ… **Production Ready** | **Challenge Completion:** 95%+

- âœ… All 7 essential requirements complete
- âœ… 2/3 bonus features complete (Visual Overlay + Timeline Analysis)
- âœ… 11,000+ words of comprehensive documentation
- âœ… 25 production-quality modules
- âœ… 4 interactive notebooks
- âœ… Multi-method validation
