{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c84397",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0948ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from analysis.temporal_evolution import TemporalAnalyzer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6de958",
   "metadata": {},
   "source": [
    "## 2. Initialize Timeline Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer with token coordinates\n",
    "token_coords_path = '../data/processed/token_coords.jsonl'\n",
    "output_dir = '../reports/figures/timeline'\n",
    "\n",
    "analyzer = TemporalAnalyzer(\n",
    "    token_coords_path=token_coords_path,\n",
    "    output_dir=output_dir\n",
    ")\n",
    "\n",
    "print(\"✓ Temporal analyzer initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad133d",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Token Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9475968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load token coordinate data\n",
    "tokens_df = analyzer.load_data()\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"  Total tokens: {len(tokens_df)}\")\n",
    "print(f\"  Unique folios: {tokens_df['folio'].nunique()}\")\n",
    "print(f\"  Unique tokens: {tokens_df['token'].nunique()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "tokens_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5738b94",
   "metadata": {},
   "source": [
    "## 4. Compute Folio-Level Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54730d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics for each folio\n",
    "folio_stats = analyzer.compute_folio_statistics()\n",
    "\n",
    "print(\"\\nFolio Statistics:\")\n",
    "folio_stats[['folio', 'token_count', 'unique_tokens', 'vocabulary_diversity', 'most_common_token']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc868ea",
   "metadata": {},
   "source": [
    "## 5. Token Frequency Evolution\n",
    "\n",
    "Analyze how the most common tokens evolve across the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most common token\n",
    "from collections import Counter\n",
    "\n",
    "all_tokens = []\n",
    "for tokens in folio_stats['tokens']:\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "top_tokens = Counter(all_tokens).most_common(5)\n",
    "\n",
    "print(\"Top 5 Most Frequent Tokens:\")\n",
    "for i, (token, count) in enumerate(top_tokens, 1):\n",
    "    print(f\"{i}. '{token}': {count} occurrences ({count/len(all_tokens)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze evolution of most common token\n",
    "most_common_token = top_tokens[0][0]\n",
    "evolution = analyzer.analyze_token_evolution(most_common_token)\n",
    "\n",
    "print(f\"\\nEvolution of '{most_common_token}':\")\n",
    "print(f\"  First appearance: {evolution['first_appearance']}\")\n",
    "print(f\"  Last appearance: {evolution['last_appearance']}\")\n",
    "print(f\"  Total occurrences: {evolution['total_occurrences']}\")\n",
    "print(f\"  Appears in {evolution['appears_in_folios']}/{len(folio_stats)} folios\")\n",
    "\n",
    "# Plot evolution\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(evolution['evolution']['order'], \n",
    "         evolution['evolution']['frequency'],\n",
    "         marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "plt.xlabel('Folio Order', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title(f\"Evolution of Token '{most_common_token}' Across Manuscript\", \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6948cc",
   "metadata": {},
   "source": [
    "## 6. Vocabulary Diversity Analysis\n",
    "\n",
    "Examine how vocabulary richness (type-token ratio) changes across folios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e34e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of vocabulary diversity\n",
    "print(\"Vocabulary Diversity Statistics:\")\n",
    "print(f\"  Mean: {folio_stats['vocabulary_diversity'].mean():.3f}\")\n",
    "print(f\"  Std Dev: {folio_stats['vocabulary_diversity'].std():.3f}\")\n",
    "print(f\"  Min: {folio_stats['vocabulary_diversity'].min():.3f} (Folio: {folio_stats.loc[folio_stats['vocabulary_diversity'].idxmin(), 'folio']})\")\n",
    "print(f\"  Max: {folio_stats['vocabulary_diversity'].max():.3f} (Folio: {folio_stats.loc[folio_stats['vocabulary_diversity'].idxmax(), 'folio']})\")\n",
    "\n",
    "# Box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(folio_stats['vocabulary_diversity'], vert=True)\n",
    "plt.ylabel('Vocabulary Diversity (Type-Token Ratio)', fontsize=12)\n",
    "plt.title('Distribution of Vocabulary Diversity Across Folios', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656b5626",
   "metadata": {},
   "source": [
    "## 7. Vocabulary Shift Detection\n",
    "\n",
    "Identify significant changes in vocabulary between adjacent folio windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20932b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect vocabulary shifts\n",
    "shifts = analyzer.detect_vocabulary_shifts(window_size=1)\n",
    "\n",
    "if not shifts.empty:\n",
    "    print(\"Vocabulary Shift Analysis:\")\n",
    "    print(f\"  Total transitions analyzed: {len(shifts)}\")\n",
    "    print(f\"  Mean Jaccard Similarity: {shifts['jaccard_similarity'].mean():.3f}\")\n",
    "    print(f\"  Mean Jensen-Shannon Divergence: {shifts['jsd_distance'].mean():.3f}\")\n",
    "    \n",
    "    # Find most significant shift\n",
    "    max_shift_idx = shifts['jsd_distance'].idxmax()\n",
    "    max_shift = shifts.iloc[max_shift_idx]\n",
    "    \n",
    "    print(f\"\\nMost Significant Vocabulary Shift:\")\n",
    "    print(f\"  Between: {max_shift['window_start']} → {max_shift['window_end']}\")\n",
    "    print(f\"  JS Divergence: {max_shift['jsd_distance']:.3f}\")\n",
    "    print(f\"  Jaccard Similarity: {max_shift['jaccard_similarity']:.3f}\")\n",
    "    print(f\"  New tokens introduced: {max_shift['new_tokens']}\")\n",
    "    print(f\"  Tokens disappeared: {max_shift['disappeared_tokens']}\")\n",
    "    \n",
    "    shifts.head(10)\n",
    "else:\n",
    "    print(\"No vocabulary shifts detected (insufficient data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e577c",
   "metadata": {},
   "source": [
    "## 8. Generate Complete Visualizations\n",
    "\n",
    "Create comprehensive timeline analysis visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate token frequency heatmap\n",
    "analyzer.visualize_token_frequency_evolution(top_n=10)\n",
    "\n",
    "print(\"✓ Token frequency heatmap generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986095ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vocabulary diversity plots\n",
    "analyzer.visualize_vocabulary_diversity()\n",
    "\n",
    "print(\"✓ Vocabulary diversity plots generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vocabulary shift visualizations\n",
    "analyzer.visualize_vocabulary_shifts()\n",
    "\n",
    "print(\"✓ Vocabulary shift plots generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533c38d",
   "metadata": {},
   "source": [
    "## 9. Generate Comprehensive Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2611cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate full timeline report\n",
    "report = analyzer.generate_timeline_report()\n",
    "\n",
    "# Preview first 2000 characters\n",
    "print(\"Timeline Analysis Report Preview:\")\n",
    "print(\"=\" * 60)\n",
    "print(report[:2000])\n",
    "print(\"\\n[... report continues ...]\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n✓ Full report saved to: {Path(output_dir).parent / 'timeline_analysis.md'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90899ca1",
   "metadata": {},
   "source": [
    "## 10. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ddbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize key findings\n",
    "print(\"KEY FINDINGS FROM TIMELINE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1. VOCABULARY DIVERSITY:\")\n",
    "diversity_std = folio_stats['vocabulary_diversity'].std()\n",
    "if diversity_std < 0.1:\n",
    "    print(f\"   → Highly consistent (σ={diversity_std:.3f})\")\n",
    "    print(f\"   → Suggests single author/scribe\")\n",
    "else:\n",
    "    print(f\"   → Significant variation (σ={diversity_std:.3f})\")\n",
    "    print(f\"   → May indicate multiple authors or topic shifts\")\n",
    "\n",
    "print(f\"\\n2. TOKEN DISTRIBUTION:\")\n",
    "top_5_percentage = sum(c for _, c in top_tokens[:5]) / len(all_tokens) * 100\n",
    "print(f\"   → Top 5 tokens: {top_5_percentage:.1f}% of all tokens\")\n",
    "if top_5_percentage > 40:\n",
    "    print(f\"   → High repetitiveness (cipher-like behavior)\")\n",
    "else:\n",
    "    print(f\"   → Moderate diversity (natural language-like)\")\n",
    "\n",
    "if not shifts.empty:\n",
    "    print(f\"\\n3. VOCABULARY SHIFTS:\")\n",
    "    mean_jsd = shifts['jsd_distance'].mean()\n",
    "    print(f\"   → Mean JS Divergence: {mean_jsd:.3f}\")\n",
    "    if mean_jsd < 0.3:\n",
    "        print(f\"   → Vocabulary remains stable throughout\")\n",
    "        print(f\"   → Consistent encoding/cipher system\")\n",
    "    else:\n",
    "        print(f\"   → Significant vocabulary shifts detected\")\n",
    "        print(f\"   → Multiple topics or encoding schemes possible\")\n",
    "\n",
    "print(f\"\\n4. TEMPORAL STRUCTURE:\")\n",
    "token_variance = folio_stats['token_count'].std() / folio_stats['token_count'].mean()\n",
    "print(f\"   → Token count variation: {token_variance:.3f}\")\n",
    "if token_variance < 0.3:\n",
    "    print(f\"   → Uniform folio structure\")\n",
    "else:\n",
    "    print(f\"   → Variable folio lengths (may indicate sections)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Timeline analysis complete! ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fb1179",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This timeline analysis provides insights into:\n",
    "\n",
    "1. **Temporal consistency** - Whether the manuscript maintains consistent linguistic patterns\n",
    "2. **Structural boundaries** - Potential section divisions or topic changes\n",
    "3. **Authorship indicators** - Evidence for single vs. multiple scribes\n",
    "4. **Encoding patterns** - Characteristics that inform decipherment strategy\n",
    "\n",
    "These findings should be:\n",
    "- Cross-referenced with manuscript illustrations and physical structure\n",
    "- Compared with known historical cipher systems\n",
    "- Validated with expanded corpus analysis\n",
    "- Integrated with other linguistic analyses (embeddings, language comparison)\n",
    "\n",
    "---\n",
    "\n",
    "*For detailed methodology and implementation, see `src/analysis/temporal_evolution.py`*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
