{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "# Set working directory to project root\n",
    "import os\n",
    "os.chdir('..')\n",
    "print(f\"üìÅ Working directory: {Path('.').resolve()}\")\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aced70",
   "metadata": {},
   "source": [
    "## 1. Load All Results Data\n",
    "\n",
    "Load hypotheses, language comparisons, and experiment metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c044fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hypotheses\n",
    "hypotheses_file = Path('reports/hypotheses/hypotheses_aggregated.jsonl')\n",
    "hypotheses = []\n",
    "if hypotheses_file.exists():\n",
    "    with open(hypotheses_file, 'r') as f:\n",
    "        for line in f:\n",
    "            hypotheses.append(json.loads(line))\n",
    "\n",
    "print(f\"üìä Loaded {len(hypotheses)} hypotheses\")\n",
    "\n",
    "# Load run hypotheses\n",
    "run_hyp_file = Path('reports/hypotheses/run_hypotheses.jsonl')\n",
    "run_hypotheses = []\n",
    "if run_hyp_file.exists():\n",
    "    with open(run_hyp_file, 'r') as f:\n",
    "        for line in f:\n",
    "            run_hypotheses.append(json.loads(line))\n",
    "\n",
    "print(f\"üìä Loaded {len(run_hypotheses)} run hypotheses\")\n",
    "\n",
    "# Load experiment metrics\n",
    "metrics_file = Path('reports/experiment_metrics.json')\n",
    "metrics = {}\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "\n",
    "print(f\"üìä Loaded experiment metrics\")\n",
    "\n",
    "# Load language comparison files\n",
    "comparison_dir = Path('reports/comparison')\n",
    "comparisons = {}\n",
    "if comparison_dir.exists():\n",
    "    for comp_file in comparison_dir.glob('*_details.json'):\n",
    "        lang = comp_file.stem.replace('_details', '')\n",
    "        with open(comp_file, 'r') as f:\n",
    "            comparisons[lang] = json.load(f)\n",
    "\n",
    "print(f\"üìä Loaded {len(comparisons)} language comparisons: {list(comparisons.keys())}\")\n",
    "\n",
    "# Load comparison metadata\n",
    "metadata_file = comparison_dir / 'comparison_metadata.json'\n",
    "comparison_metadata = {}\n",
    "if metadata_file.exists():\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        comparison_metadata = json.load(f)\n",
    "\n",
    "print(\"\\n‚úÖ All data loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb950dc",
   "metadata": {},
   "source": [
    "## 2. Hypothesis Quality Assessment\n",
    "\n",
    "Evaluate the quality, diversity, and actionability of generated hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b03e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze hypothesis diversity\n",
    "all_hyps = hypotheses + run_hypotheses\n",
    "\n",
    "# Extract tokens mentioned in prompts\n",
    "tokens_in_hypotheses = []\n",
    "for h in all_hyps:\n",
    "    prompt = h.get('prompt', '')\n",
    "    tokens = prompt.split()\n",
    "    tokens_in_hypotheses.extend(tokens)\n",
    "\n",
    "token_coverage = Counter(tokens_in_hypotheses)\n",
    "\n",
    "# Count unique response patterns\n",
    "responses = [h.get('response', '') for h in all_hyps]\n",
    "unique_responses = len(set(responses))\n",
    "\n",
    "# Model distribution\n",
    "models_used = Counter([h.get('model', 'unknown') for h in all_hyps])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"HYPOTHESIS QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä Total hypotheses: {len(all_hyps)}\")\n",
    "print(f\"üìä Unique response patterns: {unique_responses} ({unique_responses/len(all_hyps)*100:.1f}%)\")\n",
    "print(f\"üìä Tokens covered: {len(token_coverage)} unique tokens\")\n",
    "print(f\"\\nü§ñ Models used:\")\n",
    "for model, count in models_used.most_common():\n",
    "    print(f\"   - {model}: {count} hypotheses\")\n",
    "\n",
    "# Assess hypothesis specificity\n",
    "generic_phrases = ['may represent', 'common noun', 'determiner', 'frequency hint']\n",
    "specific_hypotheses = 0\n",
    "generic_hypotheses = 0\n",
    "\n",
    "for h in all_hyps:\n",
    "    response = h.get('response', '').lower()\n",
    "    if any(phrase in response for phrase in generic_phrases):\n",
    "        generic_hypotheses += 1\n",
    "    else:\n",
    "        specific_hypotheses += 1\n",
    "\n",
    "print(f\"\\nüéØ Hypothesis specificity:\")\n",
    "print(f\"   - Generic: {generic_hypotheses} ({generic_hypotheses/len(all_hyps)*100:.1f}%)\")\n",
    "print(f\"   - Specific: {specific_hypotheses} ({specific_hypotheses/len(all_hyps)*100:.1f}%)\")\n",
    "\n",
    "# Visualize token coverage\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Token coverage\n",
    "ax1 = axes[0]\n",
    "top_tokens = token_coverage.most_common(15)\n",
    "tokens_labels = [t[0] for t in top_tokens]\n",
    "tokens_counts = [t[1] for t in top_tokens]\n",
    "bars = ax1.barh(tokens_labels, tokens_counts, color='steelblue', edgecolor='black')\n",
    "ax1.set_xlabel('Hypothesis Count', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Token', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Top Tokens in Generated Hypotheses', fontsize=14, fontweight='bold')\n",
    "ax1.invert_yaxis()\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Model distribution\n",
    "ax2 = axes[1]\n",
    "model_names = list(models_used.keys())\n",
    "model_counts = list(models_used.values())\n",
    "colors = sns.color_palette('husl', len(model_names))\n",
    "ax2.pie(model_counts, labels=model_names, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "ax2.set_title('Hypothesis Generation by Model', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è CRITICAL FINDING: Most hypotheses are generic and rule-based!\")\n",
    "print(\"   Recommendation: Use more sophisticated LLMs for specific semantic hypotheses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f492d",
   "metadata": {},
   "source": [
    "## 3. Language Comparison Analysis\n",
    "\n",
    "Interpret Jensen-Shannon Divergence scores and determine which languages are most similar to Voynich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31775fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract JSD scores\n",
    "jsd_scores = {}\n",
    "for lang, data in comparisons.items():\n",
    "    if 'jsd_unigram' in data:\n",
    "        jsd_scores[lang] = {\n",
    "            'unigram': data['jsd_unigram'],\n",
    "            'bigram': data.get('jsd_bigram', None),\n",
    "            'vocab_overlap': data.get('vocab_overlap', 0),\n",
    "            'common_tokens': data.get('common_tokens_count', 0)\n",
    "        }\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LANGUAGE SIMILARITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìä Jensen-Shannon Divergence (JSD) Interpretation:\")\n",
    "print(\"   - JSD = 0.0: Identical distributions\")\n",
    "print(\"   - JSD < 0.3: Very similar\")\n",
    "print(\"   - JSD 0.3-0.5: Moderately similar\")\n",
    "print(\"   - JSD > 0.5: Very different\")\n",
    "print(\"   - JSD = 1.0: Completely different\\n\")\n",
    "\n",
    "# Create comparison dataframe\n",
    "comp_data = []\n",
    "for lang, scores in jsd_scores.items():\n",
    "    comp_data.append({\n",
    "        'Language': lang.replace('_', ' ').title(),\n",
    "        'JSD Unigram': scores['unigram'],\n",
    "        'JSD Bigram': scores['bigram'] if scores['bigram'] else np.nan,\n",
    "        'Vocab Overlap': scores['vocab_overlap'],\n",
    "        'Common Tokens': scores['common_tokens']\n",
    "    })\n",
    "\n",
    "df_comp = pd.DataFrame(comp_data).sort_values('JSD Unigram')\n",
    "\n",
    "print(\"\\nüìä Language Similarity Ranking (lower JSD = more similar):\\n\")\n",
    "print(df_comp.to_string(index=False))\n",
    "\n",
    "# Visualize comparisons\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. JSD Unigram comparison\n",
    "ax1 = axes[0, 0]\n",
    "bars = ax1.barh(df_comp['Language'], df_comp['JSD Unigram'], color='coral', edgecolor='black')\n",
    "ax1.set_xlabel('JSD Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Unigram Distribution Similarity (Lower = More Similar)', fontsize=14, fontweight='bold')\n",
    "ax1.invert_yaxis()\n",
    "ax1.axvline(x=0.3, color='green', linestyle='--', label='Very Similar Threshold', alpha=0.7)\n",
    "ax1.axvline(x=0.5, color='orange', linestyle='--', label='Moderate Threshold', alpha=0.7)\n",
    "ax1.legend()\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, df_comp['JSD Unigram']):\n",
    "    ax1.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.3f}',\n",
    "             va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# 2. JSD Bigram comparison (if available)\n",
    "ax2 = axes[0, 1]\n",
    "df_bigram = df_comp.dropna(subset=['JSD Bigram']).sort_values('JSD Bigram')\n",
    "if len(df_bigram) > 0:\n",
    "    bars2 = ax2.barh(df_bigram['Language'], df_bigram['JSD Bigram'], color='skyblue', edgecolor='black')\n",
    "    ax2.set_xlabel('JSD Score', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Bigram Distribution Similarity', fontsize=14, fontweight='bold')\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.axvline(x=0.3, color='green', linestyle='--', alpha=0.7)\n",
    "    ax2.axvline(x=0.5, color='orange', linestyle='--', alpha=0.7)\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    for bar, val in zip(bars2, df_bigram['JSD Bigram']):\n",
    "        ax2.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.3f}',\n",
    "                 va='center', fontsize=9, fontweight='bold')\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'No bigram data available', ha='center', va='center', fontsize=12)\n",
    "    ax2.set_xlim(0, 1)\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "# 3. Vocabulary overlap\n",
    "ax3 = axes[1, 0]\n",
    "df_sorted = df_comp.sort_values('Vocab Overlap', ascending=False)\n",
    "bars3 = ax3.bar(df_sorted['Language'], df_sorted['Vocab Overlap'] * 100, \n",
    "                color='lightgreen', edgecolor='black')\n",
    "ax3.set_ylabel('Overlap %', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Vocabulary Overlap with Voynich', fontsize=14, fontweight='bold')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "for bar, val in zip(bars3, df_sorted['Vocab Overlap'] * 100):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{val:.1f}%',\n",
    "             ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# 4. Common tokens count\n",
    "ax4 = axes[1, 1]\n",
    "df_sorted2 = df_comp.sort_values('Common Tokens', ascending=False)\n",
    "bars4 = ax4.bar(df_sorted2['Language'], df_sorted2['Common Tokens'],\n",
    "                color='plum', edgecolor='black')\n",
    "ax4.set_ylabel('Token Count', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Number of Common Tokens', fontsize=14, fontweight='bold')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "for bar, val in zip(bars4, df_sorted2['Common Tokens']):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2, f'{int(val)}',\n",
    "             ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate conclusions\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONCLUSIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "most_similar = df_comp.iloc[0]\n",
    "print(f\"\\n‚úÖ Most similar language: {most_similar['Language']}\")\n",
    "print(f\"   - JSD Unigram: {most_similar['JSD Unigram']:.3f}\")\n",
    "print(f\"   - Vocab overlap: {most_similar['Vocab Overlap']*100:.2f}%\")\n",
    "print(f\"   - Common tokens: {int(most_similar['Common Tokens'])}\")\n",
    "\n",
    "if most_similar['JSD Unigram'] < 0.3:\n",
    "    print(\"\\nüéØ STRONG SIMILARITY: Voynich shows very similar statistical patterns!\")\n",
    "elif most_similar['JSD Unigram'] < 0.5:\n",
    "    print(\"\\n‚ö†Ô∏è MODERATE SIMILARITY: Some structural similarities exist.\")\n",
    "else:\n",
    "    print(\"\\n‚ùå LOW SIMILARITY: Voynich appears statistically distinct from tested languages.\")\n",
    "\n",
    "print(f\"\\nüìå Recommendation: Focus analysis on {most_similar['Language']} linguistic structures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d6974",
   "metadata": {},
   "source": [
    "## 4. Statistical Pattern Analysis\n",
    "\n",
    "Analyze the statistical patterns found in the Voynich text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STATISTICAL PATTERN ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if metrics:\n",
    "    print(f\"\\nüìä Corpus Statistics:\")\n",
    "    print(f\"   - Total lines: {metrics.get('lines', 'N/A')}\")\n",
    "    print(f\"   - Total tokens: {metrics.get('tokens', 'N/A')}\")\n",
    "    print(f\"   - Vocabulary size: {metrics.get('vocab_size', 'N/A')}\")\n",
    "    print(f\"   - Hapax legomena: {metrics.get('hapax_count', 'N/A')} ({metrics.get('hapax_ratio', 0)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüìä Entropy Analysis:\")\n",
    "    entropy = metrics.get('unigram_entropy', 0)\n",
    "    print(f\"   - Unigram entropy: {entropy:.4f} bits\")\n",
    "    \n",
    "    if entropy < 3.0:\n",
    "        print(\"   ‚ö†Ô∏è LOW ENTROPY: Text shows high predictability (possible repetitive structure)\")\n",
    "    elif entropy < 4.5:\n",
    "        print(\"   ‚úÖ MODERATE ENTROPY: Similar to natural languages\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è HIGH ENTROPY: Unusually unpredictable (possible random or artificial)\")\n",
    "    \n",
    "    print(f\"\\nüìä Zipf's Law Analysis:\")\n",
    "    zipf_slope = metrics.get('zipf_slope', 0)\n",
    "    print(f\"   - Log-log slope: {zipf_slope:.4f}\")\n",
    "    \n",
    "    if -1.2 < zipf_slope < -0.8:\n",
    "        print(\"   ‚úÖ FOLLOWS ZIPF'S LAW: Consistent with natural language\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è DEVIATES FROM ZIPF'S LAW: Slope should be near -1.0\")\n",
    "        if zipf_slope > -0.8:\n",
    "            print(\"      ‚Üí More uniform distribution than typical language\")\n",
    "        else:\n",
    "            print(\"      ‚Üí More skewed distribution than typical language\")\n",
    "    \n",
    "    # Top tokens analysis\n",
    "    print(f\"\\nüìä Most Frequent Tokens:\")\n",
    "    top_unigrams = metrics.get('top_unigrams', [])\n",
    "    if top_unigrams:\n",
    "        for i, (token, count) in enumerate(top_unigrams[:10], 1):\n",
    "            freq_pct = count / metrics.get('tokens', 1) * 100\n",
    "            print(f\"   {i:2d}. '{token}': {count} occurrences ({freq_pct:.2f}%)\")\n",
    "        \n",
    "        # Calculate concentration\n",
    "        top_5_freq = sum(c for t, c in top_unigrams[:5]) / metrics.get('tokens', 1)\n",
    "        print(f\"\\n   Top 5 tokens represent {top_5_freq*100:.1f}% of all text\")\n",
    "        \n",
    "        if top_5_freq > 0.4:\n",
    "            print(\"   ‚úÖ HIGH CONCENTRATION: Similar to function words in natural language\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è LOW CONCENTRATION: Unusual for natural language\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No statistical metrics available\")\n",
    "\n",
    "# Visualize if data available\n",
    "if metrics and 'top_unigrams' in metrics:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Token frequency\n",
    "    ax1 = axes[0]\n",
    "    top_tokens = metrics['top_unigrams'][:15]\n",
    "    tokens = [t[0] for t in top_tokens]\n",
    "    counts = [t[1] for t in top_tokens]\n",
    "    bars = ax1.barh(tokens, counts, color='steelblue', edgecolor='black')\n",
    "    ax1.set_xlabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Top 15 Voynich Tokens', fontsize=14, fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Zipf's law visualization\n",
    "    ax2 = axes[1]\n",
    "    ranks = np.arange(1, len(metrics['top_unigrams']) + 1)\n",
    "    frequencies = [t[1] for t in metrics['top_unigrams']]\n",
    "    ax2.loglog(ranks, frequencies, 'o-', color='coral', markersize=8, linewidth=2)\n",
    "    ax2.set_xlabel('Rank (log scale)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Frequency (log scale)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title(\"Zipf's Law: Rank vs Frequency\", fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    # Add ideal Zipf line\n",
    "    if len(ranks) > 0:\n",
    "        ideal_zipf = frequencies[0] / ranks\n",
    "        ax2.loglog(ranks, ideal_zipf, '--', color='gray', alpha=0.5, \n",
    "                   linewidth=2, label='Ideal Zipf (slope=-1)')\n",
    "        ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422a9c6",
   "metadata": {},
   "source": [
    "## 5. Actionable Insights & Recommendations\n",
    "\n",
    "Synthesize findings into concrete next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ACTIONABLE INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Insight 1: Hypothesis quality\n",
    "if generic_hypotheses / len(all_hyps) > 0.8:\n",
    "    insights.append({\n",
    "        'category': 'Hypothesis Generation',\n",
    "        'finding': 'Over 80% of hypotheses are generic rule-based outputs',\n",
    "        'action': 'Replace local-rule model with advanced LLMs (GPT-4, Claude, or fine-tuned models)',\n",
    "        'priority': 'HIGH'\n",
    "    })\n",
    "\n",
    "# Insight 2: Language similarity\n",
    "if jsd_scores:\n",
    "    best_lang = min(jsd_scores.items(), key=lambda x: x[1]['unigram'])\n",
    "    if best_lang[1]['unigram'] < 0.5:\n",
    "        insights.append({\n",
    "            'category': 'Language Analysis',\n",
    "            'finding': f\"{best_lang[0].replace('_', ' ').title()} shows moderate structural similarity\",\n",
    "            'action': f\"Deep-dive analysis: align Voynich tokens with {best_lang[0]} morphological patterns\",\n",
    "            'priority': 'MEDIUM'\n",
    "        })\n",
    "\n",
    "# Insight 3: Statistical patterns\n",
    "if metrics:\n",
    "    hapax_ratio = metrics.get('hapax_ratio', 0)\n",
    "    if hapax_ratio > 0.5:\n",
    "        insights.append({\n",
    "            'category': 'Data Quality',\n",
    "            'finding': f'High hapax legomena ratio ({hapax_ratio*100:.0f}%) indicates small dataset or noise',\n",
    "            'action': 'Expand corpus to full manuscript transcription (all 240 folios)',\n",
    "            'priority': 'HIGH'\n",
    "        })\n",
    "    \n",
    "    entropy = metrics.get('unigram_entropy', 0)\n",
    "    if entropy < 3.5:\n",
    "        insights.append({\n",
    "            'category': 'Linguistic Structure',\n",
    "            'finding': 'Low entropy suggests high repetition or limited vocabulary',\n",
    "            'action': 'Investigate token repetition patterns and morphological analysis',\n",
    "            'priority': 'MEDIUM'\n",
    "        })\n",
    "\n",
    "# Insight 4: Missing analyses\n",
    "insights.append({\n",
    "    'category': 'Missing Analysis',\n",
    "    'finding': 'No temporal/positional analysis of token evolution',\n",
    "    'action': 'Implement timeline analysis showing token usage across manuscript sections',\n",
    "    'priority': 'MEDIUM'\n",
    "})\n",
    "\n",
    "insights.append({\n",
    "    'category': 'Missing Analysis',\n",
    "    'finding': 'No clustering visualization or semantic grouping',\n",
    "    'action': 'Generate and visualize embedding clusters with interpretive labels',\n",
    "    'priority': 'LOW'\n",
    "})\n",
    "\n",
    "# Display insights\n",
    "print(\"\\nüìã Priority Insights:\\n\")\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"{i}. [{insight['priority']}] {insight['category']}\")\n",
    "    print(f\"   Finding: {insight['finding']}\")\n",
    "    print(f\"   Action: {insight['action']}\")\n",
    "    print()\n",
    "\n",
    "# Create summary dataframe\n",
    "df_insights = pd.DataFrame(insights)\n",
    "print(\"\\nüìä Insights Summary:\\n\")\n",
    "print(df_insights[['priority', 'category', 'finding']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NEXT STEPS (IN ORDER)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. üî• Expand dataset to full manuscript (240 folios)\")\n",
    "print(\"2. üî• Implement advanced LLM hypothesis generation with scoring\")\n",
    "print(\"3. üìä Deep-dive language alignment with best-match corpus\")\n",
    "print(\"4. üìà Create temporal evolution analysis\")\n",
    "print(\"5. üéØ Generate and validate specific token mappings\")\n",
    "print(\"\\n‚úÖ Analysis complete! Ready for final report generation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b540d24",
   "metadata": {},
   "source": [
    "## 6. Export Analysis Report\n",
    "\n",
    "Generate a comprehensive markdown report with all findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c029ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate report content\n",
    "report_content = f\"\"\"# Voynich Manuscript Decoder - Results Analysis Report\n",
    "\n",
    "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This report provides a comprehensive analysis of all results generated by the Voynich Manuscript decoder pipeline, including hypothesis evaluation, language comparisons, and statistical pattern analysis.\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Hypothesis Quality**: {len(all_hyps)} hypotheses generated, with {generic_hypotheses/len(all_hyps)*100:.0f}% being generic rule-based outputs\n",
    "2. **Language Similarity**: {list(comparisons.keys())[0] if comparisons else 'N/A'} shows closest statistical match\n",
    "3. **Statistical Patterns**: {'Low' if metrics.get('unigram_entropy', 0) < 3.5 else 'Moderate'} entropy indicates {'repetitive' if metrics.get('unigram_entropy', 0) < 3.5 else 'natural'} structure\n",
    "4. **Dataset Size**: Current analysis based on {metrics.get('tokens', 'N/A')} tokens from {metrics.get('lines', 'N/A')} lines\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Hypothesis Generation Assessment\n",
    "\n",
    "### Overview\n",
    "- Total hypotheses: {len(all_hyps)}\n",
    "- Unique response patterns: {unique_responses} ({unique_responses/len(all_hyps)*100:.1f}%)\n",
    "- Tokens covered: {len(token_coverage)}\n",
    "- Models used: {', '.join(models_used.keys())}\n",
    "\n",
    "### Quality Metrics\n",
    "- **Generic hypotheses**: {generic_hypotheses} ({generic_hypotheses/len(all_hyps)*100:.1f}%)\n",
    "- **Specific hypotheses**: {specific_hypotheses} ({specific_hypotheses/len(all_hyps)*100:.1f}%)\n",
    "\n",
    "### Critical Finding\n",
    "‚ö†Ô∏è **Most hypotheses are generic and rule-based**, lacking specific semantic interpretations. This indicates the need for more sophisticated LLM models.\n",
    "\n",
    "### Recommendation\n",
    "Replace or augment the `local-rule` model with advanced language models (GPT-4, Claude-3, or fine-tuned models) to generate more specific, testable hypotheses.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Language Comparison Results\n",
    "\n",
    "### Jensen-Shannon Divergence Analysis\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if jsd_scores:\n",
    "    sorted_langs = sorted(jsd_scores.items(), key=lambda x: x[1]['unigram'])\n",
    "    report_content += \"\\n| Rank | Language | JSD Unigram | JSD Bigram | Vocab Overlap | Common Tokens |\\n\"\n",
    "    report_content += \"|------|----------|-------------|------------|---------------|---------------|\\n\"\n",
    "    for i, (lang, scores) in enumerate(sorted_langs, 1):\n",
    "        lang_name = lang.replace('_', ' ').title()\n",
    "        bigram = f\"{scores['bigram']:.3f}\" if scores['bigram'] else \"N/A\"\n",
    "        report_content += f\"| {i} | {lang_name} | {scores['unigram']:.3f} | {bigram} | {scores['vocab_overlap']*100:.1f}% | {scores['common_tokens']} |\\n\"\n",
    "    \n",
    "    best_match = sorted_langs[0]\n",
    "    report_content += f\"\\n### Best Match: {best_match[0].replace('_', ' ').title()}\\n\\n\"\n",
    "    report_content += f\"- **JSD Score**: {best_match[1]['unigram']:.3f} \"\n",
    "    \n",
    "    if best_match[1]['unigram'] < 0.3:\n",
    "        report_content += \"(Very Similar)\\n\"\n",
    "    elif best_match[1]['unigram'] < 0.5:\n",
    "        report_content += \"(Moderately Similar)\\n\"\n",
    "    else:\n",
    "        report_content += \"(Low Similarity)\\n\"\n",
    "    \n",
    "    report_content += f\"- **Vocabulary Overlap**: {best_match[1]['vocab_overlap']*100:.2f}%\\n\"\n",
    "    report_content += f\"- **Common Tokens**: {best_match[1]['common_tokens']}\\n\\n\"\n",
    "\n",
    "report_content += \"\"\"---\n",
    "\n",
    "## 3. Statistical Pattern Analysis\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if metrics:\n",
    "    report_content += f\"\"\"### Corpus Statistics\n",
    "- Lines: {metrics.get('lines', 'N/A')}\n",
    "- Tokens: {metrics.get('tokens', 'N/A')}\n",
    "- Vocabulary size: {metrics.get('vocab_size', 'N/A')}\n",
    "- Hapax legomena: {metrics.get('hapax_count', 'N/A')} ({metrics.get('hapax_ratio', 0)*100:.1f}%)\n",
    "\n",
    "### Entropy Analysis\n",
    "- **Unigram entropy**: {metrics.get('unigram_entropy', 0):.4f} bits\n",
    "\"\"\"\n",
    "    \n",
    "    entropy = metrics.get('unigram_entropy', 0)\n",
    "    if entropy < 3.0:\n",
    "        report_content += \"- **Interpretation**: LOW - High predictability (repetitive structure)\\n\"\n",
    "    elif entropy < 4.5:\n",
    "        report_content += \"- **Interpretation**: MODERATE - Similar to natural languages\\n\"\n",
    "    else:\n",
    "        report_content += \"- **Interpretation**: HIGH - Unusually unpredictable\\n\"\n",
    "    \n",
    "    report_content += f\"\"\"\\n### Zipf's Law Compliance\n",
    "- **Log-log slope**: {metrics.get('zipf_slope', 0):.4f}\n",
    "\"\"\"\n",
    "    \n",
    "    zipf_slope = metrics.get('zipf_slope', 0)\n",
    "    if -1.2 < zipf_slope < -0.8:\n",
    "        report_content += \"- **Interpretation**: ‚úÖ Follows Zipf's Law (consistent with natural language)\\n\"\n",
    "    else:\n",
    "        report_content += f\"- **Interpretation**: ‚ö†Ô∏è Deviates from Zipf's Law (expected ~-1.0)\\n\"\n",
    "\n",
    "report_content += f\"\"\"\\n---\n",
    "\n",
    "## 4. Actionable Insights\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    report_content += f\"\"\"### {i}. [{insight['priority']}] {insight['category']}\n",
    "\n",
    "**Finding**: {insight['finding']}\n",
    "\n",
    "**Recommended Action**: {insight['action']}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "report_content += \"\"\"---\n",
    "\n",
    "## 5. Next Steps\n",
    "\n",
    "1. **Expand Dataset** - Process full manuscript (240 folios) to improve statistical reliability\n",
    "2. **Upgrade Hypothesis Generation** - Implement advanced LLM models with confidence scoring\n",
    "3. **Deep Language Analysis** - Perform morphological alignment with best-match language\n",
    "4. **Temporal Analysis** - Track token evolution across manuscript sections\n",
    "5. **Hypothesis Validation** - Test generated hypotheses against corpus patterns\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The current analysis provides a foundation for understanding the Voynich Manuscript's statistical structure. While preliminary results show interesting patterns, the analysis is limited by:\n",
    "\n",
    "1. Small dataset size (sample transcription)\n",
    "2. Generic hypothesis generation\n",
    "3. Lack of temporal/positional analysis\n",
    "\n",
    "Implementing the recommended next steps will significantly improve the depth and actionability of the decoder's findings.\n",
    "\n",
    "---\n",
    "\n",
    "*Report generated by Voynich Manuscript Decoder Analysis Pipeline*\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "output_file = Path('reports/analysis_report.md')\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(f\"‚úÖ Analysis report saved to: {output_file}\")\n",
    "print(f\"üìÑ Report length: {len(report_content)} characters\")\n",
    "print(f\"\\nüéâ Complete results analysis finished!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
