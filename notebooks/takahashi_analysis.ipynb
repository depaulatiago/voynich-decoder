{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ed811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takahashi embeddings analysis\n",
    "# This notebook is split into cells for: environment, imports, params, loading, projection, clustering, plotting, and exports.\n",
    "\n",
    "\"\"\"\n",
    "Cell 1: Intro (markdown-like header).\n",
    "\"\"\"\n",
    "print('Notebook prepared: split cells will follow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0008cf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0]\n",
      "\n",
      "Installed packages (top 30 lines):\n",
      "anyio==4.11.0\n",
      "argon2-cffi==25.1.0\n",
      "argon2-cffi-bindings==25.1.0\n",
      "arrow==1.4.0\n",
      "asttokens==3.0.1\n",
      "async-lru==2.0.5\n",
      "attrs==25.4.0\n",
      "babel==2.17.0\n",
      "beautifulsoup4==4.14.2\n",
      "bleach==6.3.0\n",
      "certifi==2025.11.12\n",
      "cffi==2.0.0\n",
      "charset-normalizer==3.4.4\n",
      "comm==0.2.3\n",
      "contourpy==1.3.3\n",
      "cycler==0.12.1\n",
      "debugpy==1.8.17\n",
      "decorator==5.2.1\n",
      "defusedxml==0.7.1\n",
      "executing==2.2.1\n",
      "fastjsonschema==2.21.2\n",
      "fonttools==4.60.1\n",
      "fqdn==1.5.1\n",
      "gensim==4.4.0\n",
      "h11==0.16.0\n",
      "httpcore==1.0.9\n",
      "httpx==0.28.1\n",
      "idna==3.11\n",
      "ipykernel==7.1.0\n",
      "ipython==9.7.0\n",
      "\n",
      "Installed packages (top 30 lines):\n",
      "anyio==4.11.0\n",
      "argon2-cffi==25.1.0\n",
      "argon2-cffi-bindings==25.1.0\n",
      "arrow==1.4.0\n",
      "asttokens==3.0.1\n",
      "async-lru==2.0.5\n",
      "attrs==25.4.0\n",
      "babel==2.17.0\n",
      "beautifulsoup4==4.14.2\n",
      "bleach==6.3.0\n",
      "certifi==2025.11.12\n",
      "cffi==2.0.0\n",
      "charset-normalizer==3.4.4\n",
      "comm==0.2.3\n",
      "contourpy==1.3.3\n",
      "cycler==0.12.1\n",
      "debugpy==1.8.17\n",
      "decorator==5.2.1\n",
      "defusedxml==0.7.1\n",
      "executing==2.2.1\n",
      "fastjsonschema==2.21.2\n",
      "fonttools==4.60.1\n",
      "fqdn==1.5.1\n",
      "gensim==4.4.0\n",
      "h11==0.16.0\n",
      "httpcore==1.0.9\n",
      "httpx==0.28.1\n",
      "idna==3.11\n",
      "ipykernel==7.1.0\n",
      "ipython==9.7.0\n"
     ]
    }
   ],
   "source": [
    "# Environment & metadata\n",
    "import sys\n",
    "import subprocess\n",
    "print('Python:', sys.version.replace('\\n',' '))\n",
    "try:\n",
    "    pkgs = subprocess.check_output([sys.executable, '-m', 'pip', 'freeze']).decode('utf-8')\n",
    "    print('\\nInstalled packages (top 30 lines):')\n",
    "    print('\\n'.join(pkgs.splitlines()[:30]))\n",
    "except Exception as e:\n",
    "    print('Could not list packages:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eec9aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready. umap: True tsne: True\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    import umap\n",
    "    _has_umap = True\n",
    "except Exception:\n",
    "    _has_umap = False\n",
    "\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    _has_tsne = True\n",
    "except Exception:\n",
    "    _has_tsne = False\n",
    "\n",
    "print('Imports ready. umap:', _has_umap, 'tsne:', _has_tsne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f27edc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters set. OUTDIR: notebooks/outputs\n"
     ]
    }
   ],
   "source": [
    "# Parameters (tweakable)\n",
    "OUTDIR = Path('notebooks/outputs')\n",
    "TERMS_P = Path('models/minimal/voynich_takahashi/terms.npy')\n",
    "EMB_P = Path('models/minimal/voynich_takahashi/embeddings.npy')\n",
    "JSONL_P = Path('data/processed/voynich_takahashi.jsonl')\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Projection params\n",
    "USE_UMAP = True\n",
    "UMAP_N_NEIGHBORS = 15\n",
    "UMAP_MIN_DIST = 0.1\n",
    "TSNE_PERPLEXITY = 30\n",
    "PCA_DIM = 50\n",
    "\n",
    "# Clustering\n",
    "K = 10\n",
    "\n",
    "print('Parameters set. OUTDIR:', OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c925481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved ROOT: /home/tiago/Documents/GitHub/voynich-decoder\n",
      "Terms path: /home/tiago/Documents/GitHub/voynich-decoder/models/minimal/voynich_takahashi/terms.npy\n",
      "Embeddings path: /home/tiago/Documents/GitHub/voynich-decoder/models/minimal/voynich_takahashi/embeddings.npy\n",
      "JSONL path: /home/tiago/Documents/GitHub/voynich-decoder/data/processed/voynich_takahashi.jsonl\n",
      "Loaded terms: (5861,) embeddings: (5861, 20)\n",
      "JSONL lines: 5208\n"
     ]
    }
   ],
   "source": [
    "# Load data (adjust paths relative to notebook/workdir)\n",
    "from pathlib import Path\n",
    "cwd = Path.cwd()\n",
    "ROOT = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "TERMS_P = ROOT / 'models' / 'minimal' / 'voynich_takahashi' / 'terms.npy'\n",
    "EMB_P = ROOT / 'models' / 'minimal' / 'voynich_takahashi' / 'embeddings.npy'\n",
    "JSONL_P = ROOT / 'data' / 'processed' / 'voynich_takahashi.jsonl'\n",
    "OUTDIR = ROOT / 'notebooks' / 'outputs'\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Resolved ROOT:', ROOT)\n",
    "print('Terms path:', TERMS_P)\n",
    "print('Embeddings path:', EMB_P)\n",
    "print('JSONL path:', JSONL_P)\n",
    "\n",
    "terms = np.load(TERMS_P, allow_pickle=True)\n",
    "emb = np.load(EMB_P)\n",
    "print('Loaded terms:', terms.shape, 'embeddings:', emb.shape)\n",
    "\n",
    "lines = []\n",
    "if JSONL_P.exists():\n",
    "    with open(JSONL_P, 'r', encoding='utf-8') as fh:\n",
    "        for ln in fh:\n",
    "            try:\n",
    "                lines.append(json.loads(ln))\n",
    "            except Exception:\n",
    "                pass\n",
    "print('JSONL lines:', len(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee0d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess / normalize embeddings\n",
    "scaler = StandardScaler()\n",
    "E = scaler.fit_transform(emb)\n",
    "\n",
    "pca = PCA(n_components=min(PCA_DIM, E.shape[1]-1))\n",
    "E_p = pca.fit_transform(E)\n",
    "print('PCA reduced shape:', E_p.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e75607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection (UMAP or t-SNE)\n",
    "if USE_UMAP and _has_umap:\n",
    "    reducer = umap.UMAP(n_components=2, n_neighbors=UMAP_N_NEIGHBORS, min_dist=UMAP_MIN_DIST, metric='cosine', random_state=42)\n",
    "    proj = reducer.fit_transform(E_p)\n",
    "    method = 'umap'\n",
    "else:\n",
    "    reducer = TSNE(n_components=2, perplexity=TSNE_PERPLEXITY, random_state=42, n_iter=1000)\n",
    "    proj = reducer.fit_transform(E_p)\n",
    "    method = 'tsne'\n",
    "print('Projection method:', method, 'proj shape:', proj.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c60df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "km = KMeans(n_clusters=K, random_state=42, n_init=10)\n",
    "labels = km.fit_predict(E_p)\n",
    "print('Clusters:', np.unique(labels))\n",
    "\n",
    "if len(set(labels)) > 1:\n",
    "    try:\n",
    "        sil = silhouette_score(E_p, labels)\n",
    "        print('Silhouette score:', sil)\n",
    "    except Exception as e:\n",
    "        print('Could not compute silhouette:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c4647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters (2D)\n",
    "plt.figure(figsize=(10,8))\n",
    "pal = sns.color_palette('tab10', n_colors=K)\n",
    "for k in range(K):\n",
    "    idx = labels == k\n",
    "    plt.scatter(proj[idx,0], proj[idx,1], s=12, color=pal[k%len(pal)], label=f'cluster {k} ({idx.sum()})', alpha=0.8)\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.title(f'Takahashi embeddings projection (method={method})')\n",
    "plt.tight_layout()\n",
    "fig_path = OUTDIR / f'projection_{method}.png'\n",
    "plt.savefig(fig_path, dpi=150)\n",
    "plt.show()\n",
    "print('Saved figure to', fig_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11979204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top terms per cluster and export\n",
    "from numpy.linalg import norm\n",
    "centroids = km.cluster_centers_\n",
    "\n",
    "def top_terms_for_centroid(c, terms_vecs, terms, topk=10):\n",
    "    sims = (terms_vecs @ c) / (norm(terms_vecs, axis=1) * (norm(c)+1e-12))\n",
    "    order = np.argsort(-sims)[:topk]\n",
    "    return [(terms[i].item() if hasattr(terms[i],'item') else terms[i], float(sims[i])) for i in order]\n",
    "\n",
    "# Use E_p (PCA-reduced) as term vectors\n",
    "top_by_cluster = {}\n",
    "for k in range(K):\n",
    "    c = centroids[k]\n",
    "    top = top_terms_for_centroid(c, E_p, terms, topk=10)\n",
    "    top_by_cluster[k] = top\n",
    "\n",
    "out_terms_p = OUTDIR / 'top_terms_by_cluster.json'\n",
    "with open(out_terms_p, 'w', encoding='utf-8') as fh:\n",
    "    json.dump(top_by_cluster, fh, ensure_ascii=False, indent=2)\n",
    "print('Saved top terms per cluster to', out_terms_p)\n",
    "\n",
    "for k, items in top_by_cluster.items():\n",
    "    print(f'Cluster {k} ({(labels==k).sum()} terms):', ', '.join([t for t,s in items[:5]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814019d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary and notes\n",
    "print('Outputs saved in', OUTDIR)\n",
    "print('Files:')\n",
    "for p in sorted(OUTDIR.glob('*')):\n",
    "    print(' -', p.name)\n",
    "\n",
    "print('\\nNotebook complete. Next: run gensim training for richer embeddings or try HDBSCAN for non-parametric clusters.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
